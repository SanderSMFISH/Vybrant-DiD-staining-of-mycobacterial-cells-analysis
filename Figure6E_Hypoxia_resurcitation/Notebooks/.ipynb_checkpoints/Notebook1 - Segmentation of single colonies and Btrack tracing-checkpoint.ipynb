{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccf55c64",
   "metadata": {},
   "source": [
    "## <font color='seagreen'>Notebook1- Segmentation of single colonies and Btrack tracing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405bd5ff",
   "metadata": {},
   "source": [
    "To determine the effects of hypoxia duration on  bacterial resuscitation, time until first division and colony growth rate were extracted from our single cell time-lapse microscopy data. In this notebook we will segment and perform our tracking on the single colony data. Note paths should be adjusted when changing either imaging position or replicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63fe28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load used libraries\n",
    "import napari\n",
    "from glob import glob\n",
    "from nd2reader import ND2Reader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "from skimage import io,segmentation,data, feature, future\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from skimage import io,morphology\n",
    "import os\n",
    "from skimage.util import montage\n",
    "import btrack\n",
    "from btrack import datasets\n",
    "from scipy.ndimage import label as nlabel\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edb5e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(p, q):\n",
    "    \"\"\" \n",
    "    Return euclidean distance between points p and q\n",
    "    assuming both to have the same number of dimensions\n",
    "    \"\"\"\n",
    "    # sum of squared difference between coordinates\n",
    "    s_sq_difference = 0\n",
    "    for p_i,q_i in zip(p,q):\n",
    "        s_sq_difference += (p_i - q_i)**2\n",
    "    \n",
    "    # take sq root of sum of squared difference\n",
    "    distance = s_sq_difference**0.5\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453aa6e2",
   "metadata": {},
   "source": [
    "## Apply Napari-buds classifier on ND2 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f6726",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=glob(r'../Data/*regrowth.nd2')\n",
    "rep1=files[0]\n",
    "rep2=files[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d123f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=ND2Reader(rep2)\n",
    "images.bundle_axes = 'tyx'\n",
    "images.iter_axes = 'v'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce9823",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "\n",
    "viewer.add_image(fovs[0][67,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11346e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=glob(r'../Napari_Buds_Classifier/*')[0]\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a077fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=joblib.load(c)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21712af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_func=partial(feature.multiscale_basic_features,intensity=True, edges=True, texture=True,\n",
    "                                sigma_min=1, sigma_max=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de8e04f",
   "metadata": {},
   "source": [
    "## Batch convert classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84bf9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "v=21\n",
    "segmented_files=glob(f\"../Data/Segmented/Rep1/{v}\\\\*.tiff\")\n",
    "segmented_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a23f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "v=0\n",
    "for fov in images:\n",
    "    Path(f\"../Data/segmented/Rep1/{v}\").mkdir(parents=True, exist_ok=True)\n",
    "    tid=0\n",
    "    segmented_files=glob(f\"../Data/segmented/Rep1/{v}\\\\*.tiff\")\n",
    "    for t in fov:\n",
    "        spath=f'../Data/segmented/Rep1/{v}/{v}_{tid}.tiff'\n",
    "        if spath not in segmented_files:\n",
    "            fs=features_func(t.astype(np.uint16))\n",
    "            result = future.predict_segmenter(fs, clf)\n",
    "            #uncomment to overwrite and save prediction\n",
    "            #io.imsave(spath, result)\n",
    "        tid+=1\n",
    "    v+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d3806",
   "metadata": {},
   "source": [
    "## Stack images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c0b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=glob(r'../Data/segmented/Rep1/*')\n",
    "for file in files:\n",
    "    print(file)\n",
    "    frames=glob(os.path.join(file,f'*.tiff'))\n",
    "    try:\n",
    "        frames.remove(os.path.join(file,'stacked_img.tiff'))\n",
    "    except:\n",
    "        print('nothing to remove')\n",
    "        pass\n",
    "    frames=sorted(frames,key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "    images=[]\n",
    "    for frame in frames:\n",
    "        img=io.imread(frame)\n",
    "        img=np.where(img==1,1,0)\n",
    "        img=np.expand_dims(img, axis=0)\n",
    "        img,_=nlabel(img)\n",
    "        img=morphology.remove_small_objects(img, 300)\n",
    "        img=morphology.remove_small_holes(img, 100)\n",
    "        img=np.where(img>0,1,0)\n",
    "        images.append(img)\n",
    "    io.imsave(os.path.join(file,'stacked_img.tiff'),np.concatenate(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da94ee",
   "metadata": {},
   "source": [
    "## Batch determine earliest division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b4a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track(to_track):\n",
    "    \n",
    "    FEATURES = [\n",
    "      \"area\",\n",
    "      \"major_axis_length\",\n",
    "      \"minor_axis_length\",\n",
    "      \"orientation\",\n",
    "      \"solidity\",\n",
    "      \"centroid\"\n",
    "    ]\n",
    "    \n",
    "    seg_img=io.imread(to_track)\n",
    "    objects = btrack.utils.segmentation_to_objects(\n",
    "    seg_img, \n",
    "    properties=tuple(FEATURES),)\n",
    "    CONFIG_FILE = datasets.cell_config()\n",
    "    \n",
    "    with btrack.BayesianTracker() as tracker:\n",
    "        \n",
    "        # configure the tracker using a config file\n",
    "        tracker.configure(CONFIG_FILE)\n",
    "        tracker.max_search_radius = 50\n",
    "        tracker.tracking_updates = [\"MOTION\", \"VISUAL\"]\n",
    "        tracker.features = FEATURES\n",
    "\n",
    "        # append the objects to be tracked\n",
    "        tracker.append(objects)\n",
    "\n",
    "        # set the tracking volume\n",
    "        tracker.volume=((0, 1600), (0, 1200))\n",
    "\n",
    "        # track them (in interactive mode)\n",
    "        tracker.track(step_size=100)\n",
    "\n",
    "        # generate hypotheses and run the global optimizer\n",
    "        tracker.optimize()\n",
    "\n",
    "        # get the tracks in a format for napari visualization\n",
    "        data, properties, graph = tracker.to_napari()\n",
    "\n",
    "        # store the tracks\n",
    "        tracks = tracker.tracks\n",
    "    \n",
    "    return data,properties,graph,tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3682aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "earliest_df=pd.read_csv(f'../Results/R{i}_frame.csv')\n",
    "earliest_df.set_axis(['dup_index','d_index','index','t','centroid_x','centroid_y','v','condition','time'], axis=1,inplace=True)\n",
    "\n",
    "segments=glob(fr'../Data/segmented/Rep{i}/*/stacked_img.tiff')\n",
    "segments=sorted(segments,key=lambda x: int(x.split('\\\\')[1].split('.')[0]))\n",
    "\n",
    "CONFIG_FILE = datasets.cell_config()\n",
    "\n",
    "v=0\n",
    "final_frames=[]\n",
    "full_frames=[]\n",
    "for segment in segments:\n",
    "\n",
    "    v+=1\n",
    "    print('*****'*50)\n",
    "    print(v)\n",
    "    print('*****'*50)\n",
    "\n",
    "\n",
    "    data,properties,graph,tracker=track(segment)\n",
    "    tracking_df=pd.DataFrame(properties)\n",
    "\n",
    "    #only include starting tracces\n",
    "    starting_traces=tracking_df[tracking_df['t']==0].root.unique()\n",
    "    os_tracking_df=tracking_df[tracking_df['root'].isin(starting_traces)]\n",
    "\n",
    "    #recover centroids of traces\n",
    "    locs=pd.DataFrame(data,columns=['root','t','centroid_x','centroid_y'])\n",
    "    filt_locs=locs[locs['t']==0]\n",
    "    merged_tracking_df=pd.merge(os_tracking_df,filt_locs,on='root')\n",
    "\n",
    "    #select earlies division of proper fov\n",
    "    sp_earliest_df=earliest_df[earliest_df['v']==f'{v}']\n",
    "\n",
    "    #identify the closest track\n",
    "    coordinates_tracking=list(zip(merged_tracking_df.t_x,merged_tracking_df.centroid_x,merged_tracking_df.centroid_y))\n",
    "    coordinates_earliest_div=list(zip(sp_earliest_df.t.astype(float),sp_earliest_df.centroid_x,sp_earliest_df.centroid_y))\n",
    "\n",
    "    min_distances=[]\n",
    "    earliest_div_times=[]\n",
    "    #loop through coordinates and find closest coordinates between tracks and earliest division points\n",
    "    #save minimal distances and earliest_division times\n",
    "    if len(coordinates_tracking)==0 or len(coordinates_earliest_div)==0:\n",
    "\n",
    "        print('nothing to compare')\n",
    "\n",
    "    else:\n",
    "\n",
    "        for c1 in coordinates_tracking:\n",
    "            distances=[]\n",
    "            for c2 in coordinates_earliest_div:\n",
    "                distances.append(get_distance(c1,c2))\n",
    "            min_distances.append(min(distances))\n",
    "            earliest_div_times.append(sp_earliest_df.iloc[pd.Series(distances).idxmin()].time)\n",
    "\n",
    "        merged_tracking_df['distances']=min_distances\n",
    "        merged_tracking_df['v']=v\n",
    "        merged_tracking_df['earliest_division_times']=earliest_div_times\n",
    "\n",
    "        final_frames.append(merged_tracking_df)\n",
    "\n",
    "    full_frames.append(merged_tracking_df)\n",
    "    #tracker.export(fr\"./data/Rep{i}_{v}_tracks.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff2cac7",
   "metadata": {},
   "source": [
    "## Save traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa32f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_with_ed=pd.concat(final_frames)\n",
    "traces_with_ed.columns\n",
    "traces_with_ed['id']=traces_with_ed['root'].astype(str)+traces_with_ed['v'].astype(str)\n",
    "traces_with_ed=traces_with_ed.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f96175",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(full_frames).v.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1453c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_with_ed.v.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44472e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_with_ed['condition'] = np.where(traces_with_ed['v']<= 10, '3.5 Hypoxia', '5 Hypoxia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c86fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to save traces.\n",
    "#traces_with_ed.to_csv('../Results/all_traces_Rep1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5421d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(kind='line',data=traces_with_ed,x='t_x',y='area', size=0.5, col='condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d8c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_with_ed=pd.read_csv(fr'./traces_with_ed_Rep1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d773a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.lineplot(x='t_x',y='area',hue='condition',units='id',data=traces_with_ed, estimator=None, linewidth=0.8, alpha=0.7)\n",
    "ax.set_ylim(0,150000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fdab04",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816caf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "segmentation=io.imread(r'../Data/segmented/Rep1/19/stacked_img.tiff')\n",
    "viewer.add_image(\n",
    "    segmentation, \n",
    "    name=\"Segmentation\",\n",
    "    opacity=0.2,\n",
    ")\n",
    "\n",
    "# the track data from the tracker\n",
    "viewer.add_tracks(\n",
    "    data, \n",
    "    properties=properties, \n",
    "    graph=graph, \n",
    "    name=\"Tracks\", \n",
    "    blending=\"translucent\",\n",
    "    visible=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b692bfb",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92661714",
   "metadata": {},
   "source": [
    "In the next notebook (**Notebook1 - Segmentation of single colonies and Btrack tracing.ipynb**), we will segment the colonies in each image's time frame."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
